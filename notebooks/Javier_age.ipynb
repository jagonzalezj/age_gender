{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78103890",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942f409",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761b19dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data_path = '/home/gonzalez/Desktop/age_gender/age_gender.csv' # old data\n",
    "# url = 'https://www.kaggle.com/code/shahraizanwar/age-gender-ethnicity-prediction/data?select=age_gender.csv'"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "c219bbff",
   "metadata": {
    "heading_collapsed": true
   },
=======
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61de7b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gonzalez/Desktop/age_gender/age_gender.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15181/560202589.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/gonzalez/Desktop/age_gender/age_gender.csv'"
     ]
    }
   ],
>>>>>>> dbb0e5ac1725674c4f1940e04a2f1b5cd471c673
   "source": [
    "# processing color data from Pierre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61de7b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    " # new data from Pierre\n",
    "data_path = '/home/gonzalez/code/jagonzalezj/age_gender/raw_data/new_data.csv' \n",
    "data = pd.read_csv(data_path, encoding='utf-8')\n",
    "\n",
    "lola =[]   \n",
    "for i in range(len(data['image'])):\n",
    "    a = data['image'][i].replace('[',',').replace(']',',').replace(',','').split()\n",
    "    lola.append([int(j) for j in a])\n",
    "    \n",
    "data['image']=lola\n",
    "data.columns=['age', 'gender', 'ethnicity', 'pixels']\n",
    "\n",
    "data['ethnicity'].unique()[5:]\n",
    "for items in data['ethnicity'].unique()[5:]:\n",
    "    data = data.drop(data[data.ethnicity==items].index).copy()\n",
    "\n",
    "data = data.dropna()\n",
    "data.reindex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec1061",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loading data from google cloud to google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612cad54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')\n",
    "df=pd.read_csv('gdrive/My Drive/age_gender.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de094b9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Transforming the pixels data type into a list of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67406a11",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# images =[]\n",
    "# for fotos in range(len(data['pixels'])):\n",
    "#     X = data['pixels'][fotos].split(\" \")\n",
    "#     X = list(map(int, X))\n",
    "#     images.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382e670",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x = np.reshape(images[5000], (48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034415d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1367365",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blob = data['pixels'][0].reshape(48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c74751",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(blob, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a953707",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sns.displot(data['ethnicity']),\n",
    "#sns.displot(data['gender']), \n",
    "#sns.displot(data['age']);\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "sns.histplot(ax=axes[0], x=data['age']);\n",
    "sns.histplot(ax=axes[1], x=data['ethnicity']);\n",
    "sns.histplot(ax=axes[2], x=data['gender']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251d861",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Working with the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2f14c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# list the number of counts per age\n",
    "ages = data['age'].unique()\n",
    "counts = []\n",
    "for age in ages:\n",
    "    counts.append(np.count_nonzero(data['age']==age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f55ada",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# table with the first 15 most dense samples regarding age\n",
    "type(ages), type(counts)\n",
    "s =pd.DataFrame([ages.T, np.array(counts).T],['ages', 'counts'])\n",
    "s=s.transpose()\n",
    "more_dense = s.sort_values(by=['counts'], ascending=False)\n",
    "more_dense.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a8a04",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(data[data.age==29].index).copy()\n",
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d30e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data.age);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875dbe4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The filter of Pierre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce2309",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_clean = data.copy()\n",
    "data['points_bin'] = pd.qcut(data_clean['age'], q=10)\n",
    "\n",
    "#view updated DataFrame\n",
    "print(data)\n",
    "data['points_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039097f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925d612",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# External image manipulation funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b63a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde420cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get image\n",
    "#locattion = \"/home/gonzalez/foto.jpg\" # javier\n",
    "#locattion = \"/home/gonzalez/Paul.jpeg\" # Paul\n",
    "#locattion = \"/home/gonzalez/Konstantine.jpeg\"\n",
    "locattion = \"/home/gonzalez/ping.jpg\" # Paul\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd0703",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#base_dir = os.path.dirname(locattion)\n",
    "#image = cv2.imread(\"/home/gonzalez/foto.jpg\")\n",
    "#plt.imshow(image, cmap='gray');\n",
    "#print(f'==> image resolution {image.shape}')\n",
    "\n",
    "# from PIL import Image           # this can be used to rotate images\n",
    "# image = Image.open(locattion)\n",
    "\n",
    "# (h, w) = image.shape[:2]\n",
    "# blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "# #blob.shape\n",
    "# blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3935ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imagePath=locattion\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.3,\n",
    "    minNeighbors=3,\n",
    "    minSize=(30, 30)\n",
    ")\n",
    "\n",
    "print(\"[INFO] Found {0} Faces.\".format(len(faces)))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0),1)\n",
    "    roi_color = image[y:y + h, x:x + w]\n",
    "    #print(\"[INFO] Object found. Saving locally.\")\n",
    "    #cv2.imwrite(str(w) + str(h) + '_faces.jpg', roi_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df484e00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16,16))\n",
    "\n",
    "ax1.imshow(image) # original image\n",
    "\n",
    "ax2.imshow(roi_color) # recorted original image\n",
    "roi_color.shape\n",
    "\n",
    "img = np.mean(roi_color, axis=2) # black and white image\n",
    "ax3.imshow(img, cmap='gray');\n",
    "\n",
    "img=img[2:,2:]  # remove red line effect\n",
    "\n",
    "res_final = cv2.resize(img, dsize=(48, 48), interpolation=cv2.INTER_LINEAR)\n",
    "ax4.imshow(res_final, cmap='gray');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e2f5f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_final.shape\n",
    "res_final_ready = np.reshape(res_final, (-1, 48, 48,1))\n",
    "res_final_ready.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c6649",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model.predict(res_final_ready)\n",
    "# index = np.where(model.predict(res_final_ready)==(model.predict(res_final_ready).max()))\n",
    "# index[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48cb79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model = models.load_model('Model48_datafiltered/')\n",
    "int(model.predict(res_final_ready)[0][0])\n",
    "\n",
    "#model.predict(res_final_ready)\n",
    "#index = np.where(model.predict(res_final_ready)==(model.predict(res_final_ready).max()))\n",
    "#print(f'slot number {index[1][0]}, correspond to range {index[1][0]*step_size-step_size} to {index[1][0]*step_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7755ee0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5413b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# image conver to black and white\n",
    "#image = cv2.imread(imagePath)\n",
    "#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475cf968",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Function for transforming data numbers into data range classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0a608365",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# categorize age per range:\n",
    "def age_categorize(input_list, age_step=10):\n",
    "    '''\n",
    "    Enter the list of age into input_list and the age steps\n",
    "    with : age_step = 5;  age = 4   =>  1-5\n",
    "                          age = 12  =>  10-15                        \n",
    "    '''\n",
    "    \n",
    "    cat_age = []\n",
    "    for age in input_list:\n",
    "        \n",
    "        a = float(age)/float(age_step)\n",
    "        \n",
    "        if a > 1:\n",
    "            entero = int(a)\n",
    "            coma = a-entero\n",
    "            \n",
    "            if coma > 0:\n",
    "                entero = entero+1\n",
    "            \n",
    "            max = entero * age_step\n",
    "            min = max-(age_step-1)     \n",
    "            #cat_age.append(f'{min} to {max}')   # if the output is in the real intervale\n",
    "            cat_age.append(int(max/age_step)-1)  # if the output is in categorical int number\n",
    "        else:\n",
    "            min = 1\n",
    "            max = age_step\n",
    "            #cat_age.append(f'{min} to {max}')    # if the output is in the real intervale   \n",
    "            cat_age.append(int(max/age_step)-1)   # if the output is in categorical int number\n",
    "\n",
    "            \n",
    "    return cat_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6033ea",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Here we go with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f3f14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6a003",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X = data['pixels'].tolist()\n",
    "# X = np.reshape(X, (-1, 48, 48,1))\n",
    "\n",
    "\n",
    "X = data['pixels'].tolist()\n",
    "X = np.reshape(X, (-1, 48, 48,3))\n",
    "\n",
    "y=data['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43503b3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5110f4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "# train_generator_age=train_datagen.flow(\n",
    "#     X_train ,y_train ,batch_size=32)\n",
    "\n",
    "# test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "# test_generator_age=test_datagen.flow(\n",
    "#     X_test ,y_test ,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9196d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def initialize_model(numb_int, numb_out):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,numb_int)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "   \n",
    "    model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))          \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463a3e3",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = initialize_model(X.shape[-1], y.shape[-1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a62db1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de183bdf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='mae', patience=6, restore_best_weights=True)\n",
    "\n",
    "# earlystop=EarlyStopping(patience=6)\n",
    "# learning_rate_reduction=ReduceLROnPlateau(\n",
    "#     monitor='val_acc',\n",
    "#     patience= 3,\n",
    "#     verbose=1,\n",
    "# )\n",
    "# callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216753a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b1fda",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# history_age = model.fit(\n",
    "#     train_generator_age, \n",
    "#     epochs= 60,\n",
    "#     validation_data= test_generator_age,\n",
    "#     callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839ca07",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#history = model.fit(X_train, y_train, epochs=40, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014940e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X, y, validation_split=0.3, epochs=40, callbacks=[es], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca500e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f22a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss']);\n",
    "plt.plot(history.history['mae']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d35cd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models.save_model(model, 'Model48_linearColor')\n",
    "#model = models.load_model('Model48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d211d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b4158",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=142\n",
    "plt.imshow(X[n] );\n",
    "data.iloc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c234dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#out= model.predict(X_test)\n",
    "try_inp = np.expand_dims(X[n], axis=0)\n",
    "model.predict(try_inp)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0f02f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.shape(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01508e8a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MODEL USING DATA BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf9a64",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b0e15",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "step_size = 5\n",
    "input_list = data['age']\n",
    "cat = age_categorize(input_list, step_size)\n",
    "#pd.DataFrame(cat, data['age'].values).sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ea20a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add categorical age clasification to original dataframe\n",
    "data['class_age']=cat\n",
    "#data[['age','class_age']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4443bf5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data['class_age']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df7c87",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### perform one-hot encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(data[['class_age']])\n",
    "class_age_encoded = ohe.transform(data[['class_age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd15671",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9051a97",
   "metadata": {
    "hidden": true
   },
   "source": [
    " Using Pierre distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f262b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pierre distribution\n",
    "data_clean = data.copy()\n",
    "data['points_bin'] = pd.qcut(data_clean['age'], q=10)\n",
    "\n",
    "#view updated DataFrame\n",
    "print(data)\n",
    "data['points_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e401d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# perform one-hot encoder to the Pierre distribution\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(data[['points_bin']])\n",
    "class_age_encoded = ohe.transform(data[['points_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418f2d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for elements in range(class_age_encoded.shape[1]):      # =====> THIS IS NEED WHATHERVER HOT ENCODER USED  <=====\n",
    "    data[str(elements)]=class_age_encoded[:,elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a0cc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y=data.drop(columns=['age','ethnicity','gender', 'pixels', 'points_bin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add11fe",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finished Pierre encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472cd50",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#y=data.drop(columns=['age','ethnicity','gender', 'pixels', 'class_age'])\n",
    "#y=data.drop(columns=['age','ethnicity','gender', 'img_name', 'pixels', 'points_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a07d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data['pixels'].tolist()\n",
    "X = np.reshape(X, (-1, 48, 48,3))\n",
    "\n",
    "y = class_age_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b1c397",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d2766",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def initialize_model_catgorical(numb_int, numb_out):\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32,(3,3), padding='same',activation='relu',input_shape=(48,48,numb_int)))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.Conv2D(32,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "   \n",
    "    #model.add(layers.Flatten())\n",
    "    #model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(numb_out, activation='softmax'))   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b5318",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model = initialize_model_catgorical()\n",
    "model = initialize_model_catgorical(X.shape[-1], y.shape[-1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d274b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' ,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d3c0f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='accuracy', patience=6, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda9868",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history_cat = model.fit(X_train,y_train, validation_split=0.3, epochs=50, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afad490",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#history_cat = model.fit(X, y, validation_split=0.3, epochs=40, callbacks=[es], batch_size=32)  # the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6883912",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models.save_model(model, 'Model48_categorical_ColorData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4b4d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history_cat.history['val_accuracy']);\n",
    "plt.plot(history_cat.history['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda7242",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4e418",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=244\n",
    "plt.imshow(X[n], cmap='gray');\n",
    "#np.where(y.iloc[n]==1)[0]\n",
    "print(f\"real age is {data.iloc[n]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed54e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try_inp = np.expand_dims(X[n], axis=0)\n",
    "model.predict(try_inp).max()\n",
    "index = np.where(model.predict(try_inp)==(model.predict(try_inp).max()))\n",
    "index[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ded3c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.predict(try_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837fcf02",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try_inp = np.expand_dims(X[n], axis=0)\n",
    "model.predict(try_inp).max()\n",
    "index = np.where(model.predict(try_inp)==(model.predict(try_inp).max()))\n",
    "print(f'slot number {index[1][0]}, correspond to range {index[1][0]*step_size-step_size} to {index[1][0]*step_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64598d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# best results using colab with regression on virgen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddf859",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import csv\n",
    "\n",
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')\n",
    "data=pd.read_csv('gdrive/My Drive/age_gender.csv')\n",
    "\n",
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n",
    "\n",
    "from tensorflow.keras import Sequential, layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['pixels'].tolist()\n",
    "X = np.reshape(X, (-1, 48, 48,1))\n",
    "\n",
    "y = data['age']\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "   \n",
    "    model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))          \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "   \n",
    "    return model\n",
    "\n",
    "model = initialize_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[es])\n",
    "\n",
    "plt.plot(history.history['loss']);\n",
    "plt.plot(history.history['mae']);\n",
    "\n",
    "n=5\n",
    "out = np.reshape(X_test[n], (48, 48))\n",
    "plt.imshow(out, cmap='gray');\n",
    "y_test.iloc[n]\n",
    "\n",
    "try_inp = np.expand_dims(X_test[n], axis=0)\n",
    "model.predict(try_inp)[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4d127",
   "metadata": {},
   "source": [
    "# Combination of categorical plus linear for BW images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b6e942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 14:49:25.878017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/gonzalez/TOOLS/elmer/install//lib\n",
      "2022-06-04 14:49:25.878040: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import csv\n",
    "from tensorflow.keras import Sequential, layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c3437",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1e7299bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_regression():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "   \n",
    "    model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))          \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3bd67a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_catgorical(numb_int, numb_out):\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32,(3,3), padding='same',activation='relu',input_shape=(48,48,numb_int)))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.Conv2D(32,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    \n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "   \n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(numb_out, activation='softmax'))   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f0d74",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd26d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/gonzalez/Desktop/age_gender/age_gender.csv' # old data\n",
    "data = pd.read_csv(data_path)\n",
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43684fe8",
   "metadata": {},
   "source": [
    "## FILTERING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8d9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the number of counts per age\n",
    "ages = data['age'].unique()\n",
    "counts = []\n",
    "for age in ages:\n",
    "    counts.append(np.count_nonzero(data['age']==age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab46acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ages</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>40</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>45</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ages  counts\n",
       "26    26    2197\n",
       "0      1    1123\n",
       "28    28     918\n",
       "36    35     880\n",
       "24    24     859\n",
       "25    25     734\n",
       "31    30     724\n",
       "33    32     664\n",
       "27    27     615\n",
       "29    29     570\n",
       "42    40     526\n",
       "37    36     483\n",
       "19     2     482\n",
       "47    45     440\n",
       "23    23     426"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table with the first 15 most dense samples regarding age\n",
    "type(ages), type(counts)\n",
    "s =pd.DataFrame([ages.T, np.array(counts).T],['ages', 'counts'])\n",
    "s=s.transpose()\n",
    "more_dense = s.sort_values(by=['counts'], ascending=False)\n",
    "more_dense.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec47f333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225414790.jpg.chip.jpg</td>\n",
       "      <td>[30.0, 38.0, 50.0, 90.0, 109.0, 113.0, 126.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225417177.jpg.chip.jpg</td>\n",
       "      <td>[72.0, 81.0, 94.0, 96.0, 77.0, 85.0, 90.0, 71....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110224549512.jpg.chip.jpg</td>\n",
       "      <td>[255.0, 253.0, 252.0, 221.0, 144.0, 174.0, 165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225402690.jpg.chip.jpg</td>\n",
       "      <td>[62.0, 53.0, 55.0, 62.0, 73.0, 74.0, 86.0, 94....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225421531.jpg.chip.jpg</td>\n",
       "      <td>[28.0, 60.0, 55.0, 55.0, 74.0, 74.0, 62.0, 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110215653284.jpg.chip.jpg</td>\n",
       "      <td>[73.0, 66.0, 78.0, 108.0, 112.0, 124.0, 128.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110215848132.jpg.chip.jpg</td>\n",
       "      <td>[74.0, 89.0, 51.0, 63.0, 69.0, 80.0, 94.0, 95....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110220005370.jpg.chip.jpg</td>\n",
       "      <td>[98.0, 90.0, 90.0, 111.0, 133.0, 149.0, 169.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19158</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110220016235.jpg.chip.jpg</td>\n",
       "      <td>[57.0, 74.0, 93.0, 92.0, 110.0, 124.0, 130.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19159</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110215516060.jpg.chip.jpg</td>\n",
       "      <td>[156.0, 161.0, 139.0, 140.0, 103.0, 89.0, 95.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19160 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  ethnicity  gender                        img_name  \\\n",
       "0       10          0       0  20170110225414790.jpg.chip.jpg   \n",
       "1       10          0       0  20170110225417177.jpg.chip.jpg   \n",
       "2       10          0       0  20170110224549512.jpg.chip.jpg   \n",
       "3       10          0       0  20170110225402690.jpg.chip.jpg   \n",
       "4       10          0       0  20170110225421531.jpg.chip.jpg   \n",
       "...    ...        ...     ...                             ...   \n",
       "19155    9          0       0  20170110215653284.jpg.chip.jpg   \n",
       "19156    9          0       0  20170110215848132.jpg.chip.jpg   \n",
       "19157    9          0       0  20170110220005370.jpg.chip.jpg   \n",
       "19158    9          0       0  20170110220016235.jpg.chip.jpg   \n",
       "19159    9          0       0  20170110215516060.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [30.0, 38.0, 50.0, 90.0, 109.0, 113.0, 126.0, ...  \n",
       "1      [72.0, 81.0, 94.0, 96.0, 77.0, 85.0, 90.0, 71....  \n",
       "2      [255.0, 253.0, 252.0, 221.0, 144.0, 174.0, 165...  \n",
       "3      [62.0, 53.0, 55.0, 62.0, 73.0, 74.0, 86.0, 94....  \n",
       "4      [28.0, 60.0, 55.0, 55.0, 74.0, 74.0, 62.0, 101...  \n",
       "...                                                  ...  \n",
       "19155  [73.0, 66.0, 78.0, 108.0, 112.0, 124.0, 128.0,...  \n",
       "19156  [74.0, 89.0, 51.0, 63.0, 69.0, 80.0, 94.0, 95....  \n",
       "19157  [98.0, 90.0, 90.0, 111.0, 133.0, 149.0, 169.0,...  \n",
       "19158  [57.0, 74.0, 93.0, 92.0, 110.0, 124.0, 130.0, ...  \n",
       "19159  [156.0, 161.0, 139.0, 140.0, 103.0, 89.0, 95.0...  \n",
       "\n",
       "[19160 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(data[data.age==26].index).copy()\n",
    "data = data.drop(data[data.age<2].index).copy()\n",
    "data = data.drop(data[data.age>70].index).copy()\n",
    "\n",
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737e0c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data.age);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9bc38c",
   "metadata": {},
   "source": [
    "mirroring the images of ages les dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7508173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def pixel_mirroring(pixel):\n",
    "    '''Mirroring a pixel from the prepared dataset'''\n",
    "\n",
    "    #Turn the pixel list into an array 48,48\n",
    "    array=np.uint8(pixel.reshape((48,48)))\n",
    "\n",
    "    #Turn the array into an image object and mirror it\n",
    "    img=Image.fromarray(array, 'L')\n",
    "    img=ImageOps.mirror(img)\n",
    "\n",
    "    #Turn the image back into a pixel list\n",
    "    img=img.getdata()\n",
    "    pixel_mirror=np.array(img, dtype=np.float32)\n",
    "\n",
    "    return pixel_mirror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff2be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_amout_per_age(data):\n",
    "    ages = data['age'].unique()\n",
    "    counts = []\n",
    "    for age in ages:\n",
    "        counts.append(np.count_nonzero(data['age']==age))\n",
    "\n",
    "    type(ages), type(counts)\n",
    "    s =pd.DataFrame([ages.T, np.array(counts).T],['ages', 'counts'])\n",
    "    s=s.transpose()\n",
    "    more_dense = s.sort_values(by=['counts'], ascending=True)\n",
    "    more_dense.head(15)\n",
    "    return more_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d31bdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = count_amout_per_age(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19600db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "more = dense[dense.counts>600].copy()['ages'].unique()\n",
    "less = dense[dense.counts<600].copy()['ages'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4738af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_less = data.copy()\n",
    "data_more = data.copy()\n",
    "\n",
    "for age in more:\n",
    "    data_less = data_less.drop(data_less[data_less.age==age].index).copy()\n",
    "\n",
    "for age in less:\n",
    "    data_more = data_more.drop(data_more[data_more.age==age].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ba69780",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored = []\n",
    "for images in data_less['pixels']:\n",
    "    mirrored.append(pixel_mirroring(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db137ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_less_mirrored = data_less.copy()\n",
    "data_less_mirrored['mirrored']=mirrored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ead5feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_less_mirrored.drop(columns=['pixels'], inplace=True)\n",
    "data_less_mirrored.rename(columns={'mirrored':'pixels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e8ed1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two data frames, reste indexes\n",
    "presque = pd.concat([data_less, data_less_mirrored, data_more]).reset_index(drop=True, inplace=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f2e2dbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(presque['age']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c59d0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = presque.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ca3a4",
   "metadata": {},
   "source": [
    "Steping and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f3fe75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 10\n",
    "input_list = data['age']\n",
    "cat = age_categorize(input_list, step_size)  # ====>>  INITIALIZE THIS FUNCTION  <<=========\n",
    "\n",
    "#pd.DataFrame(cat, data['age'].values).sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "affd3a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add categorical age clasification to original dataframe\n",
    "data['points_bin']=cat\n",
    "#data[['age','class_age']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "92570744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data['points_bin']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "716e7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform one-hot encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(data[['points_bin']])\n",
    "class_age_encoded = ohe.transform(data[['points_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "662905ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elements in range(class_age_encoded.shape[1]):      # =====> THIS IS NEED WHATHERVER HOT ENCODER USED  <=====\n",
    "    data[str(elements)]=class_age_encoded[:,elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f185f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c5865",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## If using piere fiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc70d9e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pierre distribution\n",
    "data_clean = data.copy()\n",
    "data['points_bin'] = pd.qcut(data_clean['age'], q=3)\n",
    "\n",
    "#view updated DataFrame\n",
    "print(data)\n",
    "data['points_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f765eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# perform one-hot encoder to the Pierre distribution\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(data[['points_bin']])\n",
    "class_age_encoded = ohe.transform(data[['points_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439651f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for elements in range(class_age_encoded.shape[1]):\n",
    "    data[str(elements)]=class_age_encoded[:,elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d84f9",
   "metadata": {},
   "source": [
    "## categorical fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0ddfe80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pixels'].tolist()\n",
    "X = np.reshape(X, (-1, 48, 48,1))\n",
    "\n",
    "y=data.drop(columns=['age','ethnicity','gender', 'pixels', 'points_bin', 'img_name'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fa903518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "      <th>points_bin</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225414790.jpg.chip.jpg</td>\n",
       "      <td>[30.0, 38.0, 50.0, 90.0, 109.0, 113.0, 126.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225417177.jpg.chip.jpg</td>\n",
       "      <td>[72.0, 81.0, 94.0, 96.0, 77.0, 85.0, 90.0, 71....</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110224549512.jpg.chip.jpg</td>\n",
       "      <td>[255.0, 253.0, 252.0, 221.0, 144.0, 174.0, 165...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225402690.jpg.chip.jpg</td>\n",
       "      <td>[62.0, 53.0, 55.0, 62.0, 73.0, 74.0, 86.0, 94....</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225421531.jpg.chip.jpg</td>\n",
       "      <td>[28.0, 60.0, 55.0, 55.0, 74.0, 74.0, 62.0, 101...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32921</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20170116182734834.jpg.chip.jpg</td>\n",
       "      <td>[10.0, 10.0, 14.0, 9.0, 18.0, 47.0, 26.0, 31.0...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32922</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20170116182457063.jpg.chip.jpg</td>\n",
       "      <td>[225.0, 222.0, 217.0, 214.0, 225.0, 232.0, 234...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32923</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20170116182439096.jpg.chip.jpg</td>\n",
       "      <td>[62.0, 65.0, 63.0, 66.0, 66.0, 92.0, 121.0, 15...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32924</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20170116182409965.jpg.chip.jpg</td>\n",
       "      <td>[109.0, 122.0, 138.0, 152.0, 150.0, 149.0, 151...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32925</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20170116182340066.jpg.chip.jpg</td>\n",
       "      <td>[1.0, 4.0, 7.0, 4.0, 21.0, 15.0, 6.0, 14.0, 48...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32926 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  ethnicity  gender                        img_name  \\\n",
       "0       10          0       0  20170110225414790.jpg.chip.jpg   \n",
       "1       10          0       0  20170110225417177.jpg.chip.jpg   \n",
       "2       10          0       0  20170110224549512.jpg.chip.jpg   \n",
       "3       10          0       0  20170110225402690.jpg.chip.jpg   \n",
       "4       10          0       0  20170110225421531.jpg.chip.jpg   \n",
       "...    ...        ...     ...                             ...   \n",
       "32921   35          2       0  20170116182734834.jpg.chip.jpg   \n",
       "32922   35          2       0  20170116182457063.jpg.chip.jpg   \n",
       "32923   35          2       0  20170116182439096.jpg.chip.jpg   \n",
       "32924   35          2       0  20170116182409965.jpg.chip.jpg   \n",
       "32925   35          2       0  20170116182340066.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  points_bin    0  \\\n",
       "0      [30.0, 38.0, 50.0, 90.0, 109.0, 113.0, 126.0, ...           0  1.0   \n",
       "1      [72.0, 81.0, 94.0, 96.0, 77.0, 85.0, 90.0, 71....           0  1.0   \n",
       "2      [255.0, 253.0, 252.0, 221.0, 144.0, 174.0, 165...           0  1.0   \n",
       "3      [62.0, 53.0, 55.0, 62.0, 73.0, 74.0, 86.0, 94....           0  1.0   \n",
       "4      [28.0, 60.0, 55.0, 55.0, 74.0, 74.0, 62.0, 101...           0  1.0   \n",
       "...                                                  ...         ...  ...   \n",
       "32921  [10.0, 10.0, 14.0, 9.0, 18.0, 47.0, 26.0, 31.0...           3  0.0   \n",
       "32922  [225.0, 222.0, 217.0, 214.0, 225.0, 232.0, 234...           3  0.0   \n",
       "32923  [62.0, 65.0, 63.0, 66.0, 66.0, 92.0, 121.0, 15...           3  0.0   \n",
       "32924  [109.0, 122.0, 138.0, 152.0, 150.0, 149.0, 151...           3  0.0   \n",
       "32925  [1.0, 4.0, 7.0, 4.0, 21.0, 15.0, 6.0, 14.0, 48...           3  0.0   \n",
       "\n",
       "         1    2    3    4    5    6  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  \n",
       "32921  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "32922  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "32923  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "32924  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "32925  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[32926 rows x 13 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9bece510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "505/505 [==============================] - 25s 48ms/step - loss: 1.6681 - accuracy: 0.3456 - val_loss: 1.4595 - val_accuracy: 0.3968\n",
      "Epoch 2/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 1.3902 - accuracy: 0.4287 - val_loss: 1.3958 - val_accuracy: 0.4256\n",
      "Epoch 3/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 1.3177 - accuracy: 0.4565 - val_loss: 1.3072 - val_accuracy: 0.4631\n",
      "Epoch 4/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 1.2515 - accuracy: 0.4811 - val_loss: 1.3236 - val_accuracy: 0.4512\n",
      "Epoch 5/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 1.2102 - accuracy: 0.4932 - val_loss: 1.3103 - val_accuracy: 0.4547\n",
      "Epoch 6/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 1.1588 - accuracy: 0.5156 - val_loss: 1.2600 - val_accuracy: 0.4819\n",
      "Epoch 7/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 1.1215 - accuracy: 0.5302 - val_loss: 1.2310 - val_accuracy: 0.4918\n",
      "Epoch 8/50\n",
      "505/505 [==============================] - 26s 52ms/step - loss: 1.0918 - accuracy: 0.5391 - val_loss: 1.2739 - val_accuracy: 0.4777\n",
      "Epoch 9/50\n",
      "505/505 [==============================] - 27s 53ms/step - loss: 1.0500 - accuracy: 0.5569 - val_loss: 1.2506 - val_accuracy: 0.4792\n",
      "Epoch 10/50\n",
      "505/505 [==============================] - 25s 49ms/step - loss: 1.0103 - accuracy: 0.5718 - val_loss: 1.2695 - val_accuracy: 0.4791\n",
      "Epoch 11/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.9770 - accuracy: 0.5866 - val_loss: 1.3290 - val_accuracy: 0.4707\n",
      "Epoch 12/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.9507 - accuracy: 0.5999 - val_loss: 1.3294 - val_accuracy: 0.4839\n",
      "Epoch 13/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.8967 - accuracy: 0.6241 - val_loss: 1.3651 - val_accuracy: 0.4677\n",
      "Epoch 14/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.8587 - accuracy: 0.6355 - val_loss: 1.3561 - val_accuracy: 0.4941\n",
      "Epoch 15/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.8328 - accuracy: 0.6531 - val_loss: 1.4307 - val_accuracy: 0.4646\n",
      "Epoch 16/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.7843 - accuracy: 0.6736 - val_loss: 1.4771 - val_accuracy: 0.4833\n",
      "Epoch 17/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.7507 - accuracy: 0.6873 - val_loss: 1.5245 - val_accuracy: 0.4819\n",
      "Epoch 18/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.7021 - accuracy: 0.7131 - val_loss: 1.5165 - val_accuracy: 0.4729\n",
      "Epoch 19/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.6878 - accuracy: 0.7199 - val_loss: 1.7000 - val_accuracy: 0.4584\n",
      "Epoch 20/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.6403 - accuracy: 0.7382 - val_loss: 1.6249 - val_accuracy: 0.4725\n",
      "Epoch 21/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.6217 - accuracy: 0.7421 - val_loss: 1.7335 - val_accuracy: 0.4584\n",
      "Epoch 22/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.5882 - accuracy: 0.7604 - val_loss: 1.7824 - val_accuracy: 0.4672\n",
      "Epoch 23/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.5561 - accuracy: 0.7793 - val_loss: 1.8625 - val_accuracy: 0.4578\n",
      "Epoch 24/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.4926 - accuracy: 0.8040 - val_loss: 1.8600 - val_accuracy: 0.4645\n",
      "Epoch 25/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.4946 - accuracy: 0.8013 - val_loss: 1.9903 - val_accuracy: 0.4606\n",
      "Epoch 26/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.4784 - accuracy: 0.8069 - val_loss: 2.1528 - val_accuracy: 0.4655\n",
      "Epoch 27/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.4473 - accuracy: 0.8223 - val_loss: 2.2060 - val_accuracy: 0.4606\n",
      "Epoch 28/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.4291 - accuracy: 0.8325 - val_loss: 2.3557 - val_accuracy: 0.4622\n",
      "Epoch 29/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.4004 - accuracy: 0.8486 - val_loss: 2.4388 - val_accuracy: 0.4652\n",
      "Epoch 30/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3758 - accuracy: 0.8582 - val_loss: 2.5495 - val_accuracy: 0.4622\n",
      "Epoch 31/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3862 - accuracy: 0.8528 - val_loss: 2.4291 - val_accuracy: 0.4661\n",
      "Epoch 32/50\n",
      "505/505 [==============================] - 24s 47ms/step - loss: 0.3526 - accuracy: 0.8675 - val_loss: 2.5102 - val_accuracy: 0.4612\n",
      "Epoch 33/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3230 - accuracy: 0.8771 - val_loss: 2.8083 - val_accuracy: 0.4561\n",
      "Epoch 34/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3338 - accuracy: 0.8735 - val_loss: 2.8906 - val_accuracy: 0.4461\n",
      "Epoch 35/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3057 - accuracy: 0.8869 - val_loss: 2.7919 - val_accuracy: 0.4603\n",
      "Epoch 36/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3133 - accuracy: 0.8845 - val_loss: 2.9471 - val_accuracy: 0.4444\n",
      "Epoch 37/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2896 - accuracy: 0.8918 - val_loss: 2.7763 - val_accuracy: 0.4513\n",
      "Epoch 38/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3009 - accuracy: 0.8886 - val_loss: 2.8744 - val_accuracy: 0.4493\n",
      "Epoch 39/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.3233 - accuracy: 0.8822 - val_loss: 2.8111 - val_accuracy: 0.4652\n",
      "Epoch 40/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2549 - accuracy: 0.9081 - val_loss: 3.1888 - val_accuracy: 0.4651\n",
      "Epoch 41/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2461 - accuracy: 0.9087 - val_loss: 3.0392 - val_accuracy: 0.4541\n",
      "Epoch 42/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2779 - accuracy: 0.8974 - val_loss: 3.0741 - val_accuracy: 0.4613\n",
      "Epoch 43/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2482 - accuracy: 0.9088 - val_loss: 3.1084 - val_accuracy: 0.4602\n",
      "Epoch 44/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2282 - accuracy: 0.9207 - val_loss: 3.4480 - val_accuracy: 0.4633\n",
      "Epoch 45/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2364 - accuracy: 0.9151 - val_loss: 3.4090 - val_accuracy: 0.4672\n",
      "Epoch 46/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.2327 - accuracy: 0.9164 - val_loss: 3.1497 - val_accuracy: 0.4555\n",
      "Epoch 47/50\n",
      "505/505 [==============================] - 25s 50ms/step - loss: 0.2460 - accuracy: 0.9117 - val_loss: 2.8893 - val_accuracy: 0.4539\n",
      "Epoch 48/50\n",
      "505/505 [==============================] - 27s 53ms/step - loss: 0.2458 - accuracy: 0.9138 - val_loss: 3.2416 - val_accuracy: 0.4495\n",
      "Epoch 49/50\n",
      "505/505 [==============================] - 26s 51ms/step - loss: 0.2142 - accuracy: 0.9239 - val_loss: 3.1556 - val_accuracy: 0.4484\n",
      "Epoch 50/50\n",
      "505/505 [==============================] - 24s 48ms/step - loss: 0.1981 - accuracy: 0.9287 - val_loss: 3.5349 - val_accuracy: 0.4503\n"
     ]
    }
   ],
   "source": [
    "model_cat = initialize_model_catgorical(X.shape[-1], y.shape[-1])\n",
    "    \n",
    "es = EarlyStopping(monitor='accuracy', patience=6, restore_best_weights=True)\n",
    "\n",
    "model_cat.compile(optimizer='adam' ,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_cat = model_cat.fit(X_train,y_train, validation_split=0.3, epochs=50, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "076f1933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f51140a84c0>]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_cat.history['loss'])\n",
    "plt.plot(history_cat.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_model(model_cat,'Model_cat_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a29bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111701e",
   "metadata": {},
   "source": [
    "# calling once the categorical branch model is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = data['points_bin'].unique()[1]\n",
    "upper = data['points_bin'].unique()[2]\n",
    "\n",
    "cacho = data.drop(data[data.points_bin<lower].index | data[data.points_bin>=upper].index).copy()\n",
    "cacho['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping for all linear model\n",
    "Histories = []\n",
    "\n",
    "y = data['age']\n",
    "\n",
    "for i in range(len(data['points_bin'].unique())):\n",
    "\n",
    "\n",
    "    # slice the dataframe\n",
    "    \n",
    "    #lower = data['points_bin'].unique()[i].left  # ====>>  USING PIERRE FORMAT  <<=========\n",
    "    #upper = data['points_bin'].unique()[i].right\n",
    "    #cacho = data.drop(data[data.age<lower].index | data[data.age>=upper].index).copy()\n",
    "    \n",
    "    lower = data['points_bin'].unique()[i]   # ====>>  USING JAVIER FORMAT  <<=========\n",
    "    upper = data['points_bin'].unique()[i+1]\n",
    "    cacho = data.drop(data[data.points_bin<lower].index | data[data.points_bin>=upper].index).copy()\n",
    "\n",
    "    \n",
    "    # prepare the data\n",
    "    X = cacho['pixels'].tolist()\n",
    "    X = np.reshape(X, (-1, 48, 48,1))\n",
    "\n",
    "    y=cacho['age']\n",
    "\n",
    "    # split data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.3, random_state=1)\n",
    "    \n",
    "    \n",
    "    print(' ')\n",
    "    print('*****************************************************************************************')\n",
    "    print(f'STARTING MODEL =======>>>>>> {i} with age range {y.min()} to {y.max()} and {X.shape} samples')\n",
    "    print('*****************************************************************************************')\n",
    "    print(' ')\n",
    "\n",
    "\n",
    "    # initialize the model\n",
    "    model = initialize_model_regression()\n",
    "        \n",
    "    # compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    # early stopping\n",
    "    es = EarlyStopping(monitor='mae', patience=6, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    # fit\n",
    "    history = model.fit(X_train, y_train, validation_split=0.3, epochs=40, callbacks=[es])\n",
    "    \n",
    "    # save model\n",
    "    Histories.append(history)\n",
    "    \n",
    "    models.save_model(model, f'Model_linear_{y.min()}_{y.max()}')\n",
    "    \n",
    "    # delete variables to save RAM\n",
    "    del model, X, y, X_train, X_test, y_train, y_test, es, history, cacho\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e4f17",
   "metadata": {},
   "source": [
    "## Evaluation test categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b247360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pixels'].tolist()\n",
    "X = np.reshape(X, (-1, 48, 48,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33abb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=12007\n",
    "plt.imshow(X[n], cmap='gray');\n",
    "#np.where(y.iloc[n]==1)[0]\n",
    "print(f\"real age is {data.iloc[n]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_inp = np.expand_dims(X[n], axis=0)\n",
    "model_cat.predict(try_inp).max()\n",
    "index = np.where(model_cat.predict(try_inp)==(model_cat.predict(try_inp).max()))\n",
    "print(f'slot number {index[1][0]}, correspond to range {(index[1][0]+1)*step_size-step_size} to {(index[1][0]+1)*step_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22747822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cat.predict(try_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_inp = np.expand_dims(X[n], axis=0)\n",
    "# model_cat.predict(try_inp).max()\n",
    "# index = np.where(model_cat.predict(try_inp)==(model_cat.predict(try_inp).max()))\n",
    "# index[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370a375",
   "metadata": {},
   "source": [
    "## Evaluation test regresional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94327e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corresponding regresional model\n",
    "predict_model = models.load_model('Model_linear_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict regresional\n",
    "predict_model.predict(try_inp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
