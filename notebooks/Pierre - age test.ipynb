{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5602c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 07:46:44.942127: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-08 07:46:44.942377: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import csv\n",
    "from tensorflow.keras import Sequential, layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../raw_data/age_gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5b0720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31716/2643723236.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['pixels'][j]=data['pixels'][j]/255\n"
     ]
    }
   ],
   "source": [
    "data['pixels']=data['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n",
    "\n",
    "for j in range(len(data)):\n",
    "    data['pixels'][j]=data['pixels'][j]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2dc2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225414790.jpg.chip.jpg</td>\n",
       "      <td>[0.11764706, 0.14901961, 0.19607843, 0.3529412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225417177.jpg.chip.jpg</td>\n",
       "      <td>[0.28235295, 0.31764707, 0.36862746, 0.3764706...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110224549512.jpg.chip.jpg</td>\n",
       "      <td>[1.0, 0.99215686, 0.9882353, 0.8666667, 0.5647...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225402690.jpg.chip.jpg</td>\n",
       "      <td>[0.24313726, 0.20784314, 0.21568628, 0.2431372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225421531.jpg.chip.jpg</td>\n",
       "      <td>[0.10980392, 0.23529412, 0.21568628, 0.2156862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20993</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110215653284.jpg.chip.jpg</td>\n",
       "      <td>[0.28627452, 0.25882354, 0.30588236, 0.4235294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20994</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110215848132.jpg.chip.jpg</td>\n",
       "      <td>[0.2901961, 0.34901962, 0.2, 0.24705882, 0.270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110220005370.jpg.chip.jpg</td>\n",
       "      <td>[0.38431373, 0.3529412, 0.3529412, 0.43529412,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110220016235.jpg.chip.jpg</td>\n",
       "      <td>[0.22352941, 0.2901961, 0.3647059, 0.36078432,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110215516060.jpg.chip.jpg</td>\n",
       "      <td>[0.6117647, 0.6313726, 0.54509807, 0.54901963,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20998 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  ethnicity  gender                        img_name  \\\n",
       "0       10          0       0  20170110225414790.jpg.chip.jpg   \n",
       "1       10          0       0  20170110225417177.jpg.chip.jpg   \n",
       "2       10          0       0  20170110224549512.jpg.chip.jpg   \n",
       "3       10          0       0  20170110225402690.jpg.chip.jpg   \n",
       "4       10          0       0  20170110225421531.jpg.chip.jpg   \n",
       "...    ...        ...     ...                             ...   \n",
       "20993    9          0       0  20170110215653284.jpg.chip.jpg   \n",
       "20994    9          0       0  20170110215848132.jpg.chip.jpg   \n",
       "20995    9          0       0  20170110220005370.jpg.chip.jpg   \n",
       "20996    9          0       0  20170110220016235.jpg.chip.jpg   \n",
       "20997    9          0       0  20170110215516060.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [0.11764706, 0.14901961, 0.19607843, 0.3529412...  \n",
       "1      [0.28235295, 0.31764707, 0.36862746, 0.3764706...  \n",
       "2      [1.0, 0.99215686, 0.9882353, 0.8666667, 0.5647...  \n",
       "3      [0.24313726, 0.20784314, 0.21568628, 0.2431372...  \n",
       "4      [0.10980392, 0.23529412, 0.21568628, 0.2156862...  \n",
       "...                                                  ...  \n",
       "20993  [0.28627452, 0.25882354, 0.30588236, 0.4235294...  \n",
       "20994  [0.2901961, 0.34901962, 0.2, 0.24705882, 0.270...  \n",
       "20995  [0.38431373, 0.3529412, 0.3529412, 0.43529412,...  \n",
       "20996  [0.22352941, 0.2901961, 0.3647059, 0.36078432,...  \n",
       "20997  [0.6117647, 0.6313726, 0.54509807, 0.54901963,...  \n",
       "\n",
       "[20998 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(data[data.age<5].index).copy()\n",
    "data = data.drop(data[data.age>80].index).copy()\n",
    "\n",
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab419914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data5_24=data[data.age<=24]\n",
    "data40_80=data[data.age>=40]\n",
    "data25_39=data[data.age>=25]\n",
    "data25_39=data25_39[data25_39.age<40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b6046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_class(age):\n",
    "    if age<=24: return 0\n",
    "    if age<=39: return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7678314",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_class']=data['age'].apply(age_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd518ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform one-hot encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(data[['age_class']])\n",
    "class_age_encoded = ohe.transform(data[['age_class']])\n",
    "\n",
    "\n",
    "for elements in range(class_age_encoded.shape[1]):      # =====> THIS IS NEED WHATHERVER HOT ENCODER USED  <=====\n",
    "    data[str(elements)]=class_age_encoded[:,elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede5488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "      <th>age_class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225414790.jpg.chip.jpg</td>\n",
       "      <td>[0.11764706, 0.14901961, 0.19607843, 0.3529412...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225417177.jpg.chip.jpg</td>\n",
       "      <td>[0.28235295, 0.31764707, 0.36862746, 0.3764706...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110224549512.jpg.chip.jpg</td>\n",
       "      <td>[1.0, 0.99215686, 0.9882353, 0.8666667, 0.5647...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225402690.jpg.chip.jpg</td>\n",
       "      <td>[0.24313726, 0.20784314, 0.21568628, 0.2431372...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170110225421531.jpg.chip.jpg</td>\n",
       "      <td>[0.10980392, 0.23529412, 0.21568628, 0.2156862...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  ethnicity  gender                        img_name  \\\n",
       "1123   10          0       0  20170110225414790.jpg.chip.jpg   \n",
       "1124   10          0       0  20170110225417177.jpg.chip.jpg   \n",
       "1125   10          0       0  20170110224549512.jpg.chip.jpg   \n",
       "1126   10          0       0  20170110225402690.jpg.chip.jpg   \n",
       "1127   10          0       0  20170110225421531.jpg.chip.jpg   \n",
       "\n",
       "                                                 pixels  age_class    0    1  \\\n",
       "1123  [0.11764706, 0.14901961, 0.19607843, 0.3529412...          0  1.0  0.0   \n",
       "1124  [0.28235295, 0.31764707, 0.36862746, 0.3764706...          0  1.0  0.0   \n",
       "1125  [1.0, 0.99215686, 0.9882353, 0.8666667, 0.5647...          0  1.0  0.0   \n",
       "1126  [0.24313726, 0.20784314, 0.21568628, 0.2431372...          0  1.0  0.0   \n",
       "1127  [0.10980392, 0.23529412, 0.21568628, 0.2156862...          0  1.0  0.0   \n",
       "\n",
       "        2  \n",
       "1123  0.0  \n",
       "1124  0.0  \n",
       "1125  0.0  \n",
       "1126  0.0  \n",
       "1127  0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7ced74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pixels'].tolist()\n",
    "X = np.reshape(X, (-1, 48, 48,1))\n",
    "\n",
    "y=data.drop(columns=['age','ethnicity','gender', 'pixels', 'age_class', 'img_name'])\n",
    "\n",
    "X_train, X_test_age, y_train, y_test_age = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc40cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_catgorical(numb_int, numb_out):\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32,(3,3), padding='same',activation='relu',input_shape=(48,48,numb_int)))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.Conv2D(32,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # model.add(layers.Conv2D(320,(3,3), padding='same',activation='relu'))\n",
    "    # model.add(layers.Conv2D(320,(3,3), padding='same',activation='relu'))\n",
    "    model.add(layers.Conv2D(320,(3,3), padding='same',activation='relu'))\n",
    "\n",
    "\n",
    "    # model.add(layers.Conv2D(520,(3,3), padding='same',activation='relu'))\n",
    "    # model.add(layers.Conv2D(520,(3,3), padding='same',activation='relu'))\n",
    "    # model.add(layers.Conv2D(520,(3,3), padding='same',activation='relu'))\n",
    "    # model.add(layers.Conv2D(520,(3,3), padding='same',activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))    \n",
    "    model.add(layers.Dense(numb_out, activation='softmax'))   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af5dbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 07:56:10.281624: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-08 07:56:10.282470: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-RM2V0FMT): /proc/driver/nvidia/version does not exist\n",
      "2022-06-08 07:56:10.300149: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-08 07:56:10.750557: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 108361728 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/368 [..............................] - ETA: 17:57 - loss: 1.1109 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 07:56:15.651366: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18911232 exceeds 10% of free system memory.\n",
      "2022-06-08 07:56:15.651582: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18911232 exceeds 10% of free system memory.\n",
      "2022-06-08 07:56:15.666595: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 27205632 exceeds 10% of free system memory.\n",
      "2022-06-08 07:56:15.666972: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 27205632 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 25s 60ms/step - loss: 1.0394 - accuracy: 0.4787 - val_loss: 0.9751 - val_accuracy: 0.5354\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 20s 55ms/step - loss: 0.9087 - accuracy: 0.5601 - val_loss: 0.8564 - val_accuracy: 0.5891\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 20s 54ms/step - loss: 0.8412 - accuracy: 0.6013 - val_loss: 0.8473 - val_accuracy: 0.6129\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 19s 53ms/step - loss: 0.7930 - accuracy: 0.6376 - val_loss: 0.7901 - val_accuracy: 0.6320\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 20s 55ms/step - loss: 0.7585 - accuracy: 0.6521 - val_loss: 0.7560 - val_accuracy: 0.6429\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 21s 56ms/step - loss: 0.7332 - accuracy: 0.6681 - val_loss: 0.7709 - val_accuracy: 0.6381\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 20s 54ms/step - loss: 0.7012 - accuracy: 0.6775 - val_loss: 0.7322 - val_accuracy: 0.6670\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 20s 56ms/step - loss: 0.6957 - accuracy: 0.6806 - val_loss: 0.7321 - val_accuracy: 0.6680\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 22s 59ms/step - loss: 0.6646 - accuracy: 0.6970 - val_loss: 0.7178 - val_accuracy: 0.6793\n",
      "Epoch 10/50\n",
      "368/368 [==============================] - 21s 57ms/step - loss: 0.6461 - accuracy: 0.7108 - val_loss: 0.7194 - val_accuracy: 0.6789\n",
      "Epoch 11/50\n",
      "368/368 [==============================] - 21s 58ms/step - loss: 0.6342 - accuracy: 0.7151 - val_loss: 0.7116 - val_accuracy: 0.6823\n",
      "Epoch 12/50\n",
      "368/368 [==============================] - 21s 57ms/step - loss: 0.6205 - accuracy: 0.7202 - val_loss: 0.7131 - val_accuracy: 0.6810\n",
      "Epoch 13/50\n",
      "368/368 [==============================] - 20s 54ms/step - loss: 0.5987 - accuracy: 0.7272 - val_loss: 0.7311 - val_accuracy: 0.6895\n",
      "Epoch 14/50\n",
      "368/368 [==============================] - 20s 53ms/step - loss: 0.5814 - accuracy: 0.7430 - val_loss: 0.7000 - val_accuracy: 0.6847\n",
      "Epoch 15/50\n",
      "368/368 [==============================] - 20s 54ms/step - loss: 0.5709 - accuracy: 0.7432 - val_loss: 0.7241 - val_accuracy: 0.6895\n",
      "Epoch 16/50\n",
      "368/368 [==============================] - 20s 55ms/step - loss: 0.5519 - accuracy: 0.7516 - val_loss: 0.7186 - val_accuracy: 0.6728\n",
      "Epoch 17/50\n",
      "368/368 [==============================] - 20s 55ms/step - loss: 0.5428 - accuracy: 0.7588 - val_loss: 0.7713 - val_accuracy: 0.6561\n",
      "Epoch 18/50\n",
      "368/368 [==============================] - 20s 54ms/step - loss: 0.5171 - accuracy: 0.7693 - val_loss: 0.7670 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "368/368 [==============================] - 19s 53ms/step - loss: 0.5054 - accuracy: 0.7761 - val_loss: 0.7482 - val_accuracy: 0.6779\n"
     ]
    }
   ],
   "source": [
    "model_cat = initialize_model_catgorical(X.shape[-1], y.shape[-1])\n",
    "    \n",
    "es = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True)\n",
    "\n",
    "model_cat.compile(optimizer='adam' ,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_cat = model_cat.fit(X_train,y_train, validation_split=0.2, epochs=50, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3269f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 08:02:52.874951: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://108b6857-e78d-4d72-ba7e-c02164c3b79f/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../raw_data/age_model_cat.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model_cat, '../raw_data/age_model_cat.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746c221",
   "metadata": {},
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e23ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_regression():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "   \n",
    "    model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))         \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ce245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['age']\n",
    "\n",
    "X_train, X_test_age, y_train, y_test_age = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b452fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "322/322 [==============================] - 24s 69ms/step - loss: 280.2323 - mae: 12.9080 - val_loss: 721.9318 - val_mae: 22.4802\n",
      "Epoch 2/100\n",
      "322/322 [==============================] - 22s 67ms/step - loss: 188.2402 - mae: 10.5796 - val_loss: 274.0139 - val_mae: 12.9321\n",
      "Epoch 3/100\n",
      "322/322 [==============================] - 21s 66ms/step - loss: 158.3643 - mae: 9.7066 - val_loss: 107.6143 - val_mae: 8.0617\n",
      "Epoch 4/100\n",
      "322/322 [==============================] - 21s 65ms/step - loss: 146.7679 - mae: 9.3403 - val_loss: 177.3819 - val_mae: 10.3000\n",
      "Epoch 5/100\n",
      "322/322 [==============================] - 21s 66ms/step - loss: 135.3073 - mae: 8.9313 - val_loss: 107.9918 - val_mae: 7.9836\n",
      "Epoch 6/100\n",
      "322/322 [==============================] - 21s 65ms/step - loss: 126.3632 - mae: 8.5930 - val_loss: 94.5281 - val_mae: 7.5583\n",
      "Epoch 7/100\n",
      "322/322 [==============================] - 21s 67ms/step - loss: 116.6671 - mae: 8.2697 - val_loss: 96.5973 - val_mae: 7.6493\n",
      "Epoch 8/100\n",
      "322/322 [==============================] - 21s 65ms/step - loss: 113.6002 - mae: 8.2073 - val_loss: 173.7273 - val_mae: 10.0441\n",
      "Epoch 9/100\n",
      "322/322 [==============================] - 22s 67ms/step - loss: 110.7362 - mae: 8.0828 - val_loss: 108.6395 - val_mae: 7.8831\n",
      "Epoch 10/100\n",
      "322/322 [==============================] - 21s 65ms/step - loss: 103.4744 - mae: 7.7828 - val_loss: 133.6190 - val_mae: 8.8076\n",
      "Epoch 11/100\n",
      "322/322 [==============================] - 22s 67ms/step - loss: 101.8286 - mae: 7.7374 - val_loss: 97.6701 - val_mae: 7.5881\n",
      "Epoch 12/100\n",
      "322/322 [==============================] - 21s 66ms/step - loss: 95.3196 - mae: 7.5008 - val_loss: 114.7240 - val_mae: 8.1906\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "model = initialize_model_regression()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor='val_mae', patience=6, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# fit\n",
    "history = model.fit(X_train, y_train, validation_split=0.3, epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6ad327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "830ec3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=48x48 at 0x7F72B08882B0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image=Image.open('../raw_data/Other images/joe.jpg')\n",
    "\n",
    "new_size=(48,48)\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces = faceCascade.detectMultiScale(image=image,scaleFactor=1.3, minNeighbors=3, minSize=(30, 30))\n",
    "output_faces=[]\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0),1)\n",
    "    output_image = image[y:y + h, x:x + w]\n",
    "    output_faces.append(f\"{x}-{y}-{w}-{h}\")\n",
    "\n",
    "image=cv2.resize(output_image, dsize=new_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "image=np.mean(image, axis=2)\n",
    "\n",
    "image=Image.fromarray(np.uint8(image), 'L')\n",
    "\n",
    "image = image.resize(new_size)\n",
    "\n",
    "array=np.array(image.getdata()).reshape((-1, 48,48,1))\n",
    "\n",
    "array=array/255\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdf39673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52.690838]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0c0835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60013044, 0.3419605 , 0.05790902]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cat.predict(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63583da",
   "metadata": {},
   "source": [
    "# Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c80308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eth=joblib.load('../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1a4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b1199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
